# -*- coding: utf-8 -*-
"""travel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TAiTq8eEPeA-FoziUPAWxoSknB-GGY5K
"""

# pip install openai langchain langchain-openai streamlit
import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# OpenAI API í‚¤ ì„¤ì •(colab)
# from google.colab import userdata
# api_key = userdata.get('opanai_key')
api_key = st.secrets["OPENAI_API_KEY"]

template = """
ë„ˆëŠ” í•œêµ­ ì—¬í–‰ ì „ë¬¸ê°€ì•¼.
ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¡°ê±´ì— ë§ëŠ” ì—¬í–‰ì§€ë¥¼ 3ê³³ ì¶”ì²œí•´ì¤˜.
ì¶”ì²œ ì´ìœ ë„ ê°„ë‹¨íˆ ì¨ì¤˜.

ì…ë ¥: {user_input}

---
í˜•ì‹:
1. ì—¬í–‰ì§€ëª… - ì¶”ì²œ ì´ìœ 
2. ì—¬í–‰ì§€ëª… - ì¶”ì²œ ì´ìœ 
3. ì—¬í–‰ì§€ëª… - ì¶”ì²œ ì´ìœ 
"""

prompt = PromptTemplate(template=template, input_variables=["user_input"])
llm = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo", openai_api_key=api_key)

# âœ… ìµœì‹  ë°©ì‹: LLMChain ì—†ì´ ì§ì ‘ ì—°ê²°
#chain = LLMChain(llm=llm, prompt=prompt)
chain = prompt | llm

# --- Streamlit UI ---
st.title("ğŸ‡°ğŸ‡· ì—¬í–‰ì§€ ì¶”ì²œ ì±—ë´‡")

user_input = st.text_input("ì—¬í–‰ ì¡°ê±´ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ì„œìš¸ ê·¼êµ ìì—° ì—¬í–‰ì§€, ë´„ ë‹¹ì¼ì¹˜ê¸° ë“±)")

if st.button("ì¶”ì²œë°›ê¸°") and user_input:
    with st.spinner("ì¶”ì²œ ì¤‘ì…ë‹ˆë‹¤..."):
        result = chain.run({"user_input": user_input})
        st.success("ì¶”ì²œ ì™„ë£Œ!")
        st.text_area("ì¶”ì²œ ê²°ê³¼", result, height=200)

# response = chain.run({"user_input": "ì„œìš¸ì—ì„œ ë‹¹ì¼ì¹˜ê¸° ê°€ëŠ¥í•œ ìì—° ì—¬í–‰ì§€ ì¶”ì²œí•´ì¤˜"})
# print(response)